{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2925bf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1524\n",
      "1524\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ppg_file =(os.listdir(\"./dataverse_files/ppg\"))\n",
    "labels_file =( os.listdir(\"./dataverse_files/labels\"))\n",
    "print(len(labels_file))\n",
    "print(len(ppg_file))\n",
    "x = np.array([ppg_file,labels_file])\n",
    "pid = set()\n",
    "for i in ppg_file:\n",
    "    pid.add(i[:-8])\n",
    "\n",
    "labels_pid = set()\n",
    "for i in pid:\n",
    "    path_l = f'{i}_labels.npy'\n",
    "    # print(path_l)\n",
    "    if path_l in labels_pid:\n",
    "        print(path_l)\n",
    "\n",
    "\n",
    "Xt = []\n",
    "Yt = []\n",
    "Xcv = []\n",
    "for i in range(len(ppg_file)):\n",
    "    ippg = np.load(f\"dataverse_files/ppg/{ppg_file[i]}\")\n",
    "    ilabels = np.load(f\"dataverse_files/labels/{ppg_file[i][:-8]}_labels.npy\")\n",
    "    # X[30*i:30*i+30,:] = ippg\n",
    "    mean_dev = 0\n",
    "    sum_dev = 0\n",
    "    for j in ippg:\n",
    "        sum_dev+=np.std(j)\n",
    "\n",
    "    mean_dev = sum_dev/30\n",
    "    Xc = []\n",
    "    for j in range(30):\n",
    "        if np.std(ippg[j])>=0.75*mean_dev:\n",
    "            Xt.append(ippg[j])\n",
    "            Yt.append(ilabels[j])\n",
    "            Xc.append(ippg[j])\n",
    "        \n",
    "    Xcv.append(np.array(Xc).flatten())\n",
    "    # Y[30*i:30*i+30,:] = ilabels\n",
    "    \n",
    "\n",
    "X = np.array(Xt)\n",
    "Y = np.array(Yt)\n",
    "# Xz = np.array(Xcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af86b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "def normalize_array(arr, mode='minmax', range_min=-1, range_max=1):\n",
    "    mean = np.mean(arr)\n",
    "    max = np.max(arr)\n",
    "    min = np.min(arr)\n",
    "\n",
    "    normalized_array = (arr-mean)/(max-min)\n",
    "    return normalized_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaf80ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9e4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import stft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "class STFT_LR :\n",
    "    def __init__(self,X,Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_normalized = np.zeros_like(X)\n",
    "    def print_data(self):\n",
    "        print(self.features)\n",
    "\n",
    "    def normalize_data(self):\n",
    "        for i in range(X.shape[0]):\n",
    "            mean = np.mean(X[i])\n",
    "            max = np.max(X[i])\n",
    "            min = np.min(X[i])\n",
    "            self.X_normalized[i] = (X[i] - mean)/(max-min)\n",
    "    \n",
    "    def normalize_sample(self,arr):\n",
    "        min = np.min(arr)\n",
    "        mean = np.mean(arr)\n",
    "        max = np.max(arr)\n",
    "        normie = (arr-mean)/(max-min)\n",
    "        return normie\n",
    "\n",
    "    def stft_coeff(self):\n",
    "        features = []\n",
    "        for signal in X:\n",
    "            f, t, Zxx = stft(signal, nperseg=125)\n",
    "            features.append(np.abs(Zxx).flatten()[:1000])\n",
    "        self.features = np.array(features)\n",
    "\n",
    "    def get_features(self,signal):\n",
    "        features =[]\n",
    "        f,t,Zxx = stft(signal,nperseg=125)\n",
    "        features.append(np.abs(Zxx).flatten()[:1000])\n",
    "        return features\n",
    "\n",
    "    def split_data(self):\n",
    "        self.X_train_split, self.X_test_split, self.y_train_split, self.y_test_split = train_test_split(self.features, self.Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    def train_model(self):\n",
    "        self.normalize_data()\n",
    "        self.stft_coeff()\n",
    "        self.split_data()\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(self.X_train_split, self.y_train_split)\n",
    "        # Predictions\n",
    "        y_pred = self.model.predict(self.X_test_split)\n",
    "\n",
    "        # Evaluation\n",
    "        mae = mean_absolute_error(self.y_test_split, y_pred)\n",
    "        mse = mean_squared_error(self.y_test_split, y_pred)\n",
    "        print(f\"MAE: {mae}, MSE: {mse}\")\n",
    "        del self.X\n",
    "        del self.Y\n",
    "        del self.X_train_split\n",
    "        del self.X_test_split\n",
    "        del self.y_train_split\n",
    "        del self.y_test_split\n",
    "        del self.features\n",
    "    \n",
    "    def predict(self,data_sample):\n",
    "        n_sample = self.normalize_sample(data_sample)\n",
    "        features = self.get_features(n_sample)\n",
    "        predictions = self.model.predict(features)\n",
    "        return predictions\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a128b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 11.38327316300784, MSE: 216.76268535617263\n"
     ]
    }
   ],
   "source": [
    "t = STFT_LR(X,Y)\n",
    "t.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2b63892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[123.45645219  54.31031672]] [76.2 48.9]\n"
     ]
    }
   ],
   "source": [
    "i = -1\n",
    "pred = t.predict(X[i])\n",
    "print(pred,Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c245a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"models/pipeline.pkl\", 'wb') as f:\n",
    "    pkl.dump(t,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11842425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import stft\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "class STFT_LR:\n",
    "    def __init__(self, X=None, Y=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.model = None\n",
    "        self.nperseg = 125\n",
    "        self.n_features = 1000  # number of STFT coefficients to keep\n",
    "\n",
    "    def normalize_sample(self, arr):\n",
    "        min_val = np.min(arr)\n",
    "        max_val = np.max(arr)\n",
    "        mean_val = np.mean(arr)\n",
    "        return (arr - mean_val) / (max_val - min_val + 1e-6)\n",
    "\n",
    "    def get_features(self, signal):\n",
    "        signal = self.normalize_sample(signal)\n",
    "        _, _, Zxx = stft(signal, nperseg=self.nperseg)\n",
    "        features = np.abs(Zxx).flatten()[:self.n_features]\n",
    "        return features\n",
    "\n",
    "    def prepare_features(self):\n",
    "        self.features = np.array([self.get_features(sig) for sig in self.X])\n",
    "\n",
    "    def split_data(self):\n",
    "        self.X_train_split, self.X_test_split, self.y_train_split, self.y_test_split = train_test_split(\n",
    "            self.features, self.Y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "    def train_model(self):\n",
    "        self.prepare_features()\n",
    "        self.split_data()\n",
    "        self.model = LinearRegression()\n",
    "        self.model.fit(self.X_train_split, self.y_train_split)\n",
    "        y_pred = self.model.predict(self.X_test_split)\n",
    "        mae = mean_absolute_error(self.y_test_split, y_pred)\n",
    "        mse = mean_squared_error(self.y_test_split, y_pred)\n",
    "        print(f\"MAE: {mae}, MSE: {mse}\")\n",
    "\n",
    "    def predict(self, signal):\n",
    "        features = self.get_features(signal).reshape(1, -1)\n",
    "        return self.model.predict(features)\n",
    "\n",
    "    def save_model(self, path=\"stft_lr_model.pkl\"):\n",
    "        joblib.dump({\n",
    "            \"model\": self.model,\n",
    "            \"nperseg\": self.nperseg,\n",
    "            \"n_features\": self.n_features\n",
    "        }, path)\n",
    "        print(f\"Model saved to {path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path=\"stft_lr_model.pkl\"):\n",
    "        data = joblib.load(path)\n",
    "        model = STFT_LR()\n",
    "        model.model = data[\"model\"]\n",
    "        model.nperseg = data[\"nperseg\"]\n",
    "        model.n_features = data[\"n_features\"]\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "693710cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 11.212909357551862, MSE: 209.31230631116486\n",
      "Model saved to stft_lr_model.pkl\n",
      "Predicted value: [[111.7678073   64.65520955]]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model = STFT_LR(X, Y)\n",
    "model.train_model()\n",
    "model.save_model(\"stft_lr_model.pkl\")\n",
    "\n",
    "# Prediction later\n",
    "loaded_model = STFT_LR.load_model(\"stft_lr_model.pkl\")\n",
    "pred = loaded_model.predict(X[-1])\n",
    "print(\"Predicted value:\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d56b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "\n",
    "@register_keras_serializable()\n",
    "class STFTLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, nperseg, frame_step, fft_length, n_features, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.nperseg = nperseg\n",
    "        self.frame_step = frame_step\n",
    "        self.fft_length = fft_length\n",
    "        self.n_features = n_features\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        mean = tf.reduce_mean(x, axis=1, keepdims=True)\n",
    "        max_ = tf.reduce_max(x, axis=1, keepdims=True)\n",
    "        min_ = tf.reduce_min(x, axis=1, keepdims=True)\n",
    "        normed = (x - mean) / (max_ - min_ + 1e-6)\n",
    "\n",
    "        stft_out = tf.signal.stft(normed,\n",
    "                                  frame_length=self.nperseg,\n",
    "                                  frame_step=self.frame_step,\n",
    "                                  fft_length=self.fft_length,\n",
    "                                  pad_end=True)\n",
    "        mag = tf.abs(stft_out)\n",
    "        flat = tf.reshape(mag, [tf.shape(mag)[0], -1])\n",
    "        return flat[:, :self.n_features]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.n_features)\n",
    "\n",
    "\n",
    "\n",
    "class STFTLinearTF:\n",
    "    def __init__(self, nperseg=125, frame_step=25, fft_length=125, n_features=3900, signal_length=3750):\n",
    "        self.nperseg = nperseg\n",
    "        self.frame_step = frame_step\n",
    "        self.fft_length = fft_length\n",
    "        self.n_features = n_features\n",
    "        self.signal_length = signal_length\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _stft_layer(self, x):\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        mean = tf.reduce_mean(x, axis=1, keepdims=True)\n",
    "        max_ = tf.reduce_max(x, axis=1, keepdims=True)\n",
    "        min_ = tf.reduce_min(x, axis=1, keepdims=True)\n",
    "        normed = (x - mean) / (max_ - min_ + 1e-6)\n",
    "\n",
    "        stft_out = tf.signal.stft(normed,\n",
    "                                  frame_length=self.nperseg,\n",
    "                                  frame_step=self.frame_step,\n",
    "                                  fft_length=self.fft_length,\n",
    "                                  pad_end=True)\n",
    "        mag = tf.abs(stft_out)\n",
    "        flat = tf.reshape(mag, [tf.shape(mag)[0], -1])\n",
    "        return flat[:, :self.n_features]\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = tf.keras.Input(shape=(self.signal_length,))\n",
    "        features = STFTLayer(self.nperseg, self.frame_step, self.fft_length, self.n_features)(inputs)\n",
    "        output = tf.keras.layers.Dense(64,use_bias=True)(features)\n",
    "        output = tf.keras.layers.Dense(32,use_bias=True)(output)\n",
    "        output = tf.keras.layers.Dense(1,use_bias=True)(output)\n",
    "        model = tf.keras.Model(inputs, output)\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "\n",
    "    def train(self, X, y, epochs=20, batch_size=3):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "        for i in range(5):\n",
    "            self.model.fit(self.X_train, self.y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "        print(\"Training completed.\")\n",
    "\n",
    "    def predict(self, signal):\n",
    "        signal = np.array(signal).reshape(1, self.signal_length).astype(np.float32)\n",
    "        return self.model.predict(signal)\n",
    "\n",
    "    def save_model(self, path=\"stft_tf_model.keras\"):\n",
    "        self.model.save(path)\n",
    "        print(f\"Model saved at {path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path=\"stft_tf_model.keras\"):\n",
    "        instance = STFTLinearTF()\n",
    "        instance.model = tf.keras.models.load_model(path)\n",
    "        print(f\"Model loaded from {path}\")\n",
    "        return instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2254f167",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'output' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# X = np.random.randn(100, 3750).astype(np.float32)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m stft_model \u001b[38;5;241m=\u001b[39m \u001b[43mSTFTLinearTF\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m stft_model\u001b[38;5;241m.\u001b[39mtrain(X, y)\n\u001b[1;32m      7\u001b[0m stft_model\u001b[38;5;241m.\u001b[39msave_model()\n",
      "Cell \u001b[0;32mIn[60], line 46\u001b[0m, in \u001b[0;36mSTFTLinearTF.__init__\u001b[0;34m(self, nperseg, frame_step, fft_length, n_features, signal_length)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features \u001b[38;5;241m=\u001b[39m n_features\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal_length \u001b[38;5;241m=\u001b[39m signal_length\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[60], line 67\u001b[0m, in \u001b[0;36mSTFTLinearTF._build_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignal_length,))\n\u001b[1;32m     66\u001b[0m features \u001b[38;5;241m=\u001b[39m STFTLayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnperseg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfft_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features)(inputs)\n\u001b[0;32m---> 67\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m,use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\u001b[43moutput\u001b[49m)\n\u001b[1;32m     68\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m,use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(features)\n\u001b[1;32m     69\u001b[0m output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m,use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(output)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'output' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# X = np.random.randn(100, 3750).astype(np.float32)\n",
    "y = Y.T[0].reshape(-1,1)\n",
    "\n",
    "stft_model = STFTLinearTF()\n",
    "stft_model.train(X, y)\n",
    "\n",
    "stft_model.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41454454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from stft_tf_model.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Prediction: [[107.46011]] Original :[131.   51.2] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and predict\n",
    "loaded = STFTLinearTF.load_model()\n",
    "i = -32\n",
    "print(\"Prediction:\", loaded.predict(X[i]), f\"Original :{Y[i]} \" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026931db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e26a7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.random.randn(100, 3750).astype(np.float32)\n",
    "y = np.random.uniform(50, 150, size=(100, 1)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "982d092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[103.4214]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft_model.predict(X[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stft_layer( x):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "\n",
    "    # Normalize input\n",
    "    mean = tf.reduce_mean(x, axis=1, keepdims=True)\n",
    "    max_ = tf.reduce_max(x, axis=1, keepdims=True)\n",
    "    min_ = tf.reduce_min(x, axis=1, keepdims=True)\n",
    "    normed = (x - mean) / (max_ - min_ + 1e-6)\n",
    "\n",
    "    # Compute STFT\n",
    "    stft = tf.signal.stft(normed,\n",
    "                            frame_length=125,\n",
    "                            frame_step=125,\n",
    "                            fft_length=125,\n",
    "                            pad_end=True)\n",
    "\n",
    "    magnitude = tf.abs(stft)  # Take magnitude of STFT\n",
    "    flat = tf.reshape(magnitude, [-1, 1000])  # Flatten STFT output\n",
    "    return flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9186110d",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 3780 values, but the requested shape has 1000 [Op:Reshape] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tt \u001b[38;5;241m=\u001b[39m \u001b[43m_stft_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m, in \u001b[0;36m_stft_layer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     11\u001b[0m stft \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mstft(normed,\n\u001b[1;32m     12\u001b[0m                         frame_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m125\u001b[39m,\n\u001b[1;32m     13\u001b[0m                         frame_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m125\u001b[39m,\n\u001b[1;32m     14\u001b[0m                         fft_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m125\u001b[39m,\n\u001b[1;32m     15\u001b[0m                         pad_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m magnitude \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mabs(stft)  \u001b[38;5;66;03m# Take magnitude of STFT\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m flat \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmagnitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Flatten STFT output\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flat\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:GPU:0}} Input to reshape is a tensor with 3780 values, but the requested shape has 1000 [Op:Reshape] name: "
     ]
    }
   ],
   "source": [
    "tt = _stft_layer(X[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192257b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcd8aa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10199dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40450, 3750)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372442c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
